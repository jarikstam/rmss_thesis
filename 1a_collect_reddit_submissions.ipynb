{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorporated-brown",
   "metadata": {},
   "source": [
    "# Collecting Reddit submissions\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import regex as re\n",
    "import sqlite3\n",
    "\n",
    "import utils\n",
    "from params import sql_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-plate",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search parameters\n",
    "# the keys are the parameter names (see https://pushshift.io/api-parameters/ for possible parameters)\n",
    "param_dict = {'subreddit':'movies',\n",
    "              'title':\"Official Discussion\",\n",
    "              'size':1000, # 1000 is the maximum number that can be collected per single request. No reason to change this.\n",
    "             }\n",
    "\n",
    "# Keys to collect from submissions\n",
    "submission_keys = ('id', 'title', 'score', 'num_comments', 'url', 'created_utc')\n",
    "\n",
    "# Define submission_limit, the number of submissions to be obtained by the API\n",
    "submission_limit = 100000\n",
    "\n",
    "# Define location and name of SQL database, create a connection object\n",
    "conn = sqlite3.connect(sql_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-classification",
   "metadata": {},
   "source": [
    "## Create SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL table for submissions if it does not yet exist\n",
    "sql_create_submissions_table = \"\"\" CREATE TABLE IF NOT EXISTS submissions (\n",
    "                                    submission_id text PRIMARY KEY,\n",
    "                                    title text,\n",
    "                                    score integer,\n",
    "                                    num_comments integer,\n",
    "                                    url text,\n",
    "                                    created integer\n",
    "                                ); \"\"\"\n",
    "\n",
    "with conn:\n",
    "    utils.interact_with_db(conn, sql_create_submissions_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-classics",
   "metadata": {},
   "source": [
    "## Find oldest collected submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to add more submissions:\n",
    "try:\n",
    "    with conn:\n",
    "        param_dict['before'] = utils.interact_with_db(conn, \n",
    "                                                      '''SELECT min(created) FROM submissions;''', \n",
    "                                                      fetch='cur.fetchone()[0]')\n",
    "        \n",
    "        print(f\"Oldest submission found is from {datetime.fromtimestamp(param_dict['before'])}\")\n",
    "except:\n",
    "    print(\"Didn't find anything. Either there is no data or something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-explanation",
   "metadata": {},
   "source": [
    "## Collect submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on: https://github.com/SeyiAgboola/Reddit-Data-Mining/blob/master/Using_Pushshift_Module_to_extract_Submissions.ipynb\n",
    "print(f\"Starting at {datetime.now()}\")\n",
    "sub_count = 0\n",
    "n_submission_keys = len(submission_keys)\n",
    "\n",
    "# Collect first set of submissions\n",
    "# We need to run this function outside the loop first to get the updated before variable\n",
    "data = utils.get_pushshift_data(param_dict)\n",
    "\n",
    "print(f\"The youngest submission that fits the criteria is from: {datetime.fromtimestamp(data[0]['created_utc'])}\")\n",
    "\n",
    "with tqdm(total=submission_limit) as pbar:\n",
    "    while len(data) > 0: \n",
    "        if sub_count < submission_limit:\n",
    "            \n",
    "            # Select relevant data from each submission in data \n",
    "            submissions_data = [utils.collect_submission_data(submission, keys=submission_keys) for submission in data]\n",
    "            \n",
    "            # Add data to database\n",
    "            with conn:\n",
    "                n_submissions = utils.add_rows(conn, 'submissions', n_submission_keys, submissions_data)\n",
    "                \n",
    "            # Update counter and tqdm\n",
    "            sub_count+= n_submissions\n",
    "            pbar.update(n_submissions)\n",
    "                \n",
    "            # Set the new 'before' parameter\n",
    "            param_dict['before'] = data[-1]['created_utc']\n",
    "            \n",
    "            # Collect next set of submissions\n",
    "            data = utils.get_pushshift_data(param_dict)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Reached submission limit at {datetime.now()}\")\n",
    "            print(f\"Didn't collect submissions posted before {datetime.fromtimestamp(param_dict['before'])}\")\n",
    "            break\n",
    "    \n",
    "\n",
    "print(f\"Finished at {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
