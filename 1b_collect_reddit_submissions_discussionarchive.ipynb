{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorporated-brown",
   "metadata": {},
   "source": [
    "# Collecting Reddit submissions\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ambient-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import regex as re\n",
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "import importlib\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "warming-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'D:\\\\Python\\\\Thesis\\\\utils.py'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-plate",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "distinct-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search parameters\n",
    "# the keys are the parameter names (see https://pushshift.io/api-parameters/ for possible parameters)\n",
    "param_dict = {'subreddit':'discussionarchive',\n",
    "              'size':1000, # 1000 is the maximum number that can be collected per single request. No reason to change this.\n",
    "              'is_self': \"false\",\n",
    "             }\n",
    "\n",
    "# Keys to collect from submissions\n",
    "submission_keys = ('id', 'title', 'score', 'num_comments', 'url', 'created_utc')\n",
    "\n",
    "# Define submission_limit, the number of submissions to be obtained by the API\n",
    "submission_limit = 100000\n",
    "\n",
    "# Define location and name of SQL database, create a connection object\n",
    "sql_db = './data/film_discussions'\n",
    "conn = sqlite3.connect(sql_db)\n",
    "\n",
    "discussionarchive_submissions_pushshift = 'data/discussionarchive_submissions_pushshift.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ordinary-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    submission_ids = utils.get_submission_ids(conn, 'submissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-explanation",
   "metadata": {},
   "source": [
    "## Collect submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ethical-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2022-02-12 17:55:02.734003\n",
      "The youngest submission that fits the criteria is from: 2022-01-15 00:02:24\n",
      "Finished at 2022-02-12 17:55:30.538722\n"
     ]
    }
   ],
   "source": [
    "# Based on: https://github.com/SeyiAgboola/Reddit-Data-Mining/blob/master/Using_Pushshift_Module_to_extract_Submissions.ipynb\n",
    "print(f\"Starting at {datetime.now()}\")\n",
    "sub_count = 0\n",
    "archive_data = set()\n",
    "\n",
    "# Collect first set of submissions\n",
    "# We need to run this function outside the loop first to get the updated before variable\n",
    "data = utils.get_pushshift_data(param_dict)\n",
    "\n",
    "print(f\"The youngest submission that fits the criteria is from: {datetime.fromtimestamp(data[0]['created_utc'])}\")\n",
    "\n",
    "while len(data) > 0: \n",
    "    if sub_count < submission_limit:\n",
    "        \n",
    "        for submission in data:\n",
    "            try:\n",
    "                url = re.findall(\"comments/([^/]+)\", submission['url'])[0]\n",
    "                archive_data.add(url)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Set the new 'before' parameter\n",
    "        param_dict['before'] = data[-1]['created_utc']\n",
    "\n",
    "        # Collect next set of submissions\n",
    "        data = utils.get_pushshift_data(param_dict)\n",
    "        \n",
    "        sub_count += 100\n",
    "\n",
    "    else:\n",
    "        print(f\"Reached submission limit at {datetime.now()}\")\n",
    "        print(f\"Didn't collect submissions posted before {datetime.fromtimestamp(param_dict['before'])}\")\n",
    "        break\n",
    "    \n",
    "\n",
    "print(f\"Finished at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "simple-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n"
     ]
    }
   ],
   "source": [
    "print(len(archive_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "centered-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(discussionarchive_submissions_pushshift,'w') as f:\n",
    "    for i in archive_data:\n",
    "        f.write(i)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "velvet-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1774\n"
     ]
    }
   ],
   "source": [
    "print(len(submission_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "established-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "archive_data.difference_update(submission_ids)\n",
    "\n",
    "print(len(archive_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cloudy-mobility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'195vjx',\n",
       " '196cjz',\n",
       " '1ew8kd',\n",
       " '1fdwlf',\n",
       " '1fdx03',\n",
       " '1gbcth',\n",
       " '1grz85',\n",
       " '1grzrc',\n",
       " '1hl7hz',\n",
       " '1i4o8n',\n",
       " '1j2um6',\n",
       " '1k05aj',\n",
       " '1kgqf9',\n",
       " '1kx7yg',\n",
       " '1n83l8',\n",
       " '1n83za',\n",
       " '1np3cf',\n",
       " '1o82lz',\n",
       " '1pnuw3',\n",
       " '1r6vqg',\n",
       " '1rs512',\n",
       " '1s96c5',\n",
       " '1tbxm2',\n",
       " '1tbxrn',\n",
       " '1tpbj4',\n",
       " '1tpbsi',\n",
       " '1uwxhh',\n",
       " '1v2iqp',\n",
       " '1xobpv',\n",
       " '1ze5f8',\n",
       " '1zesnn',\n",
       " '20ejot',\n",
       " '23bo2s',\n",
       " '24ibyf',\n",
       " '2b2k07',\n",
       " '2e8kte',\n",
       " '2ev8ss',\n",
       " '2gtkdi',\n",
       " '3n03k6',\n",
       " '3x2oyf',\n",
       " '487kb1',\n",
       " '488mq3',\n",
       " '4cchdw',\n",
       " '5mvnt5',\n",
       " '5wdqod',\n",
       " '5wevxz',\n",
       " '6tyynf',\n",
       " '6vzaae',\n",
       " '706ydq',\n",
       " '73g2fx',\n",
       " '761r2y',\n",
       " '769d5d',\n",
       " '77j3ty',\n",
       " '795pgl',\n",
       " '7agfes',\n",
       " '7doxvl',\n",
       " '7eoph7',\n",
       " '7gs900',\n",
       " '7ik3cb',\n",
       " '7ldw3m',\n",
       " '7mrl6t',\n",
       " '7ovyyn',\n",
       " '7ptn7y',\n",
       " '7t1ndd',\n",
       " '7xvumf',\n",
       " '81bwds',\n",
       " '81cz97',\n",
       " '833jvx',\n",
       " '8mmla7',\n",
       " '8pa372',\n",
       " '8pg3cd',\n",
       " '8r7d6q',\n",
       " '8yf1pd',\n",
       " '928hxl',\n",
       " '92ij8o',\n",
       " '962sh1',\n",
       " '9bplvq',\n",
       " '9dpqjg',\n",
       " '9fxw74',\n",
       " '9n9qjv',\n",
       " '9pf3kg',\n",
       " '9r6tcs',\n",
       " '9t6qga',\n",
       " '9vg4og',\n",
       " 'a1huet',\n",
       " 'a4qc91',\n",
       " 'a5mkir',\n",
       " 'a6qtnh',\n",
       " 'a9gjba',\n",
       " 'agxe41',\n",
       " 'ajfym7',\n",
       " 'ajg4a2',\n",
       " 'auexh3',\n",
       " 'augsew',\n",
       " 'b17u86',\n",
       " 'b763vf',\n",
       " 'b94d8c',\n",
       " 'bbvo53',\n",
       " 'bc0tsl',\n",
       " 'begw0j',\n",
       " 'bgnl7y',\n",
       " 'bh8lpn',\n",
       " 'bk33kl',\n",
       " 'bk35hv',\n",
       " 'bp20f1',\n",
       " 'bxi6qu',\n",
       " 'c0dqkf',\n",
       " 'c2nokl',\n",
       " 'c2ntqo',\n",
       " 'c7y18a',\n",
       " 'cqz48p',\n",
       " 'cqzfam',\n",
       " 'd6o37u',\n",
       " 'dd0ynj',\n",
       " 'djb0k1',\n",
       " 'dmidcu',\n",
       " 'dmir2v',\n",
       " 'dmjs2m',\n",
       " 'dpqt2y',\n",
       " 'dt0h5f',\n",
       " 'dt0v6z',\n",
       " 'e6l8bc',\n",
       " 'e9nzp9',\n",
       " 'e9o399',\n",
       " 'ef4mtn',\n",
       " 'emi5z3',\n",
       " 'epu0qu',\n",
       " 'f047qa',\n",
       " 'f1i94m',\n",
       " 'f7aqro',\n",
       " 'fe2xer',\n",
       " 'fyk1xa',\n",
       " 'fyk6mu',\n",
       " 'fykcv7',\n",
       " 'gkfd18',\n",
       " 'hgx7p8',\n",
       " 'i16usz',\n",
       " 'ieqn5i',\n",
       " 'ieqoxw',\n",
       " 'im7etj',\n",
       " 'j7r5di',\n",
       " 'j7rf2f',\n",
       " 'jcmq8s',\n",
       " 'jdshnp',\n",
       " 'jgfimy',\n",
       " 'jpj6go',\n",
       " 'ldxu57',\n",
       " 'ldxwd6',\n",
       " 'ldxyuh',\n",
       " 'ldy0zz',\n",
       " 'le4da6',\n",
       " 'le4g5c',\n",
       " 'lyizxz',\n",
       " 'lyj52m',\n",
       " 'lyjb21',\n",
       " 'lyji1j',\n",
       " 'lyjmq1',\n",
       " 'lyjri3',\n",
       " 'm7y4se',\n",
       " 'me3za3',\n",
       " 'me41jq',\n",
       " 'me44dl',\n",
       " 'mnwmd5',\n",
       " 'mnwp34',\n",
       " 'mnwrj5',\n",
       " 'mnwuau',\n",
       " 'nmi6ga',\n",
       " 'rlqxul'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-extra",
   "metadata": {},
   "source": [
    "## Find submission metadata\n",
    "\n",
    "Only works for 13 submissions. Pushshift doesn't seem to be complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "prescription-monster",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = \",\".join(archive_data)\n",
    "url= f\"https://api.pushshift.io/reddit/search/submission/?ids={ids}\"\n",
    "\n",
    "r = requests.get(url)\n",
    "data = r.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dimensional-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reminder: /r/movies 31 Days of Horror starts tomorrow with Suspiria!\n",
      "Official Late-Comer Megathread - Batman v. Superman: Dawn of Justice [SPOILERS]\n",
      "Official Oscar post game thread 2016\n",
      "/r/movies Oscars 2017: Official Post-Game Thread\n",
      "Official Oscar Thread 2014\n",
      "Official Live Thread - World Premiere of \"Star Wars: The Force Awakens\" [SPOILERS]\n",
      "Official Oscar Thread 2016\n",
      "/r/movies Golden Globes 2016: Official Post-Game Thread\n",
      "Official Oscar Thread 2017\n",
      "/r/movies Oscars 2019: Official Post-Game Thread\n",
      "Live Thread - Avengers: Endgame [SPOILERS]\n",
      "Official Oscars Thread 2019\n",
      "/r/movies Official 2018 Golden Globes Post-Game Thread\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(i['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
