{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-expansion",
   "metadata": {},
   "source": [
    "## Collect daily keyword counts from Twitter\n",
    "\n",
    "- Code based on: https://towardsdatascience.com/an-extensive-guide-to-collecting-tweets-from-twitter-api-v2-for-academic-research-using-python-3-518fcb71df2a\n",
    "- Note: can only do 300 requests per 15-minute window (https://developer.twitter.com/en/docs/twitter-api/rate-limits). Given that each requests finds 31 days this means that I can only request one full timeperiod (2006-2022) per 15 minutes. Time to grab a coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from time import perf_counter\n",
    "from datetime import datetime\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "# I created a .py file where I saved the Twitter bearer token as a string\n",
    "from twitter_keys import bearer_token\n",
    "from params import count_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files\n",
    "metoo_file = 'data/metoo_daily_count.json'\n",
    "blm_file = 'data/blm_daily_count.json'\n",
    "black_file = 'data/black_daily_count.json'\n",
    "oscars_not_blm_file = 'data/oscars_not_blm_daily_count.json'\n",
    "oscars_file = 'data/oscars_daily_count.json'\n",
    "metoo2_file = 'data/metoo2_daily_count.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search parameters\n",
    "# See: https://developer.twitter.com/en/docs/twitter-api/tweets/counts/api-reference/get-tweets-counts-all\n",
    "\n",
    "search_url=\"https://api.twitter.com/2/tweets/counts/all\"\n",
    "\n",
    "keyword_metoo = \"#metoo OR metoo\" # API isn't case sensitive, 'OR' means any\n",
    "keyword_metoo2 = \"#metoo\"\n",
    "keyword_blm = \"#blm OR blm OR #blacklivesmatter OR blacklivesmatter\"\n",
    "keyword_black = \"#blacklivesmatter OR blacklivesmatter\"\n",
    "keyword_oscars_not_blm = \"(#oscarssowhite OR oscarssowhite) -blm -#blm -blacklivesmatter -#blacklivesmatter\"\n",
    "keyword_oscars = \"#oscarssowhite OR oscarssowhite\"\n",
    "\n",
    "start_time = \"2006-03-21T00:00:00.000Z\" # Day of the firt ever tweet.\n",
    "end_time = \"2022-02-24T00:00:00.000Z\"\n",
    "granularity = \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(keyword, start_time, end_time, granularity, search_url=\"https://api.twitter.com/2/tweets/counts/all\"):\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time,\n",
    "                    'granularity': granularity,\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "headers = create_headers(bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a single use\n",
    "url = create_url(keyword_metoo, start_time,end_time, granularity)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through full pagination\n",
    "\n",
    "perf_start = perf_counter()\n",
    "flag = True\n",
    "next_token = None\n",
    "counts = []\n",
    "url = create_url(keyword_metoo2, start_time,end_time, granularity)\n",
    "total_tweet_count = 0\n",
    "\n",
    "while flag:\n",
    "    json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "    result_count = json_response['meta']['total_tweet_count']\n",
    "    \n",
    "    counts.extend(json_response['data'])\n",
    "    total_tweet_count += result_count\n",
    "\n",
    "    if 'next_token' in json_response['meta']:\n",
    "        next_token = json_response['meta']['next_token']\n",
    "\n",
    "    else:            \n",
    "        flag = False\n",
    "        next_token = None\n",
    "        \n",
    "print(f\"Collected {total_tweet_count} tweets in {int(perf_counter()-perf_start)} seconds. Finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# #metoo or metoo: collected 27,599,446  tweets in 44 seconds\n",
    "# #blm OR blm OR #blacklivesmatter OR blacklivesmatter collected 307,992,432  tweets in 57 seconds\n",
    "# blacklivesmatter OR #blacklivesmatter Collected 67,752,610 tweets in 44 seconds. Finished at 2022-05-11 12:54:27\n",
    "# oscars_not_blm Collected 769,166 tweets in 42 seconds\n",
    "# oscarssowhite Collected 776,538 tweets in 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metoo2_file, 'w') as outfile:\n",
    "    json.dump(counts, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-wagner",
   "metadata": {},
   "source": [
    "## Combine into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "metoo = pd.read_json(metoo_file)\n",
    "metoo2 = pd.read_json(metoo2_file)\n",
    "blm = pd.read_json(blm_file)\n",
    "black = pd.read_json(black_file)\n",
    "oscars_not_blm = pd.read_json(oscars_not_blm_file)\n",
    "oscars = pd.read_json(oscars_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "metoo.rename(columns={\"tweet_count\": \"MeToo\"}, inplace=True)\n",
    "metoo2.rename(columns={\"tweet_count\": \"MeTooX\"}, inplace=True)\n",
    "blm.rename(columns={\"tweet_count\": \"BLM\"}, inplace=True)\n",
    "black.rename(columns={\"tweet_count\": \"BlackLivesMatter\"}, inplace=True)\n",
    "oscars_not_blm.rename(columns={\"tweet_count\": \"OscarsSoWhite -BLM\"}, inplace=True)\n",
    "oscars.rename(columns={\"tweet_count\": \"OscarsSoWhite\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metoo.merge(blm, how='outer', on=['start', 'end'])\n",
    "df = df.merge(metoo2, how='outer', on=['start', 'end'])\n",
    "df = df.merge(black, how='outer', on=['start', 'end'])\n",
    "#df.rename(columns={\"tweet_count_x\": \"MeToo\", \"tweet_count_y\": \"BLM\"}, inplace=True)\n",
    "\n",
    "df = df.merge(oscars_not_blm, how='outer', on=['start', 'end'])\n",
    "df = df.merge(oscars, how='outer', on=['start', 'end'])\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['start'])\n",
    "df.drop(columns=['end', 'start'], inplace=True)\n",
    "#df = df.loc[:, ['Date', 'MeToo', 'BLM', 'Oscars Not BLM']]\n",
    "df = df.loc[:, ['Date', 'MeToo', 'MeTooX', 'BLM', 'BlackLivesMatter','OscarsSoWhite', 'OscarsSoWhite -BLM']]\n",
    "#df = dates.merge(df, how='outer', on='Date')\n",
    "df['Date'] = df['Date'].dt.date\n",
    "df.fillna(0, inplace=True)\n",
    "df['MeToo'] = df['MeToo'].astype(int)\n",
    "df['BLM'] = df['BLM'].astype(int)\n",
    "df['BlackLivesMatter'] = df['BlackLivesMatter'].astype(int)\n",
    "df['OscarsSoWhite -BLM'] = df['OscarsSoWhite -BLM'].astype(int)\n",
    "df['OscarsSoWhite'] = df['OscarsSoWhite'].astype(int)\n",
    "\n",
    "\n",
    "df.sort_values('Date', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('OscarsSoWhite', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['MeToo', 'BLM', 'OscarsSoWhite -BLM'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"MeTooX\": \"MeToo\", \"BlackLivesMatter\": \"BLM\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(count_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-think",
   "metadata": {},
   "source": [
    "## Testing keyword functionality\n",
    "Conclusion: they work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search parameters\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "max_results = 500\n",
    "\n",
    "params = {\n",
    "    'query': keyword_metoo,\n",
    "    'end_time': end_time,\n",
    "    'max_results': max_results,\n",
    "    'tweet.fields':'geo,public_metrics,lang'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a single use\n",
    "json_response = connect_to_endpoint(search_url, headers, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the 'OR' operator works as aspected (i.e., as any 'if any is true'). It does.\n",
    "\n",
    "for i in json_response['data']:\n",
    "    j = i['text'].lower()\n",
    "    if \"#metoo\" in j:\n",
    "        if re.search(\"(?<!#)metoo\", j):\n",
    "            print(i['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
