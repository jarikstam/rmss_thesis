{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controversial-victorian",
   "metadata": {},
   "source": [
    "# Collecting Reddit comments\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-referral",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "complicated-billy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define search parameters\n",
    "comment_attributes = ('comment.id',\n",
    "                      'submission.id',\n",
    "                      'comment.body',\n",
    "                      'str(comment.author)', # need to convert author to string, otherwise it's a class instance.\n",
    "                      'comment.score',\n",
    "                      'comment.created_utc')\n",
    "\n",
    "# Define comment_limit, the number of comments to be obtained\n",
    "comment_limit = 3000000\n",
    "\n",
    "# Define location and name of SQL database, create a connection object\n",
    "sql_db = './data/film_discussions'\n",
    "conn = sqlite3.connect(sql_db)\n",
    "\n",
    "# Creating a Reddit-instance in PRAW with my personal Reddit username, password etc.\n",
    "# Before handing in the project I removed the praw.ini file from this folder, which is why it now gives an error message\n",
    "# See: https://praw.readthedocs.io/en/latest/getting_started/configuration/prawini.html\n",
    "reddit_praw_id = \"Jarik\"\n",
    "reddit = praw.Reddit(reddit_praw_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-dance",
   "metadata": {},
   "source": [
    "## Create SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electric-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_create_comments_table = \"\"\"CREATE TABLE IF NOT EXISTS comments (\n",
    "                                comment_id text PRIMARY KEY,\n",
    "                                submission_id text,\n",
    "                                body text,\n",
    "                                author text,\n",
    "                                score integer,\n",
    "                                created integer,\n",
    "                                FOREIGN KEY (submission_id) REFERENCES submissions (submission_id)\n",
    "                            );\"\"\"\n",
    "\n",
    "with conn:\n",
    "    utils.interact_with_db(conn, sql_create_comments_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-violence",
   "metadata": {},
   "source": [
    "## Determine for which submissions I still need to collect comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cognitive-river",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 466 submissions for which no comments have been gathered\n"
     ]
    }
   ],
   "source": [
    "# List submission IDs\n",
    "# Because I didn't download all the comments in one go, the difference_update allows me to continue where I left off.  \n",
    "\n",
    "with conn:\n",
    "    submission_ids = utils.get_submission_ids(conn, 'submissions')\n",
    "    sub_ids_comments = utils.get_submission_ids(conn, 'comments')\n",
    "\n",
    "# Update difference   \n",
    "submission_ids.difference_update(sub_ids_comments)\n",
    "print(f\"There are {len(submission_ids)} submissions for which no comments have been gathered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "animal-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEL\n",
    "# Selecting the first 700 submissions (or do submsissions less than 6 months old?)\n",
    "\n",
    "with conn:\n",
    "    submission_ids = utils.get_submission_ids(conn, 'submissions LIMIT 300 OFFSET 700') # WHERE created > 1627839158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aboriginal-bryan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEL\n",
    "len(submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "central-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEL\n",
    "len(submission_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-diagnosis",
   "metadata": {},
   "source": [
    "## Collect comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "comprehensive-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2022-02-13 20:16:51.523966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 512/512 [10:04:59<00:00, 70.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at 2022-02-14 06:21:51.252218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting at {datetime.now()}\")\n",
    "comment_count = 0\n",
    "n_comment_attributes = len(comment_attributes)\n",
    "submission_errors = set()\n",
    "\n",
    "for submission_id in tqdm(submission_ids):\n",
    "\n",
    "    if comment_count < comment_limit:\n",
    "        try:\n",
    "            # Collect comments\n",
    "            comments_data = utils.get_comments_data(reddit, submission_id, comment_attributes=comment_attributes)\n",
    "\n",
    "            # Save the comments to the database\n",
    "            with conn:\n",
    "                n_comments = utils.add_rows(conn, 'comments', n_comment_attributes, comments_data)\n",
    "\n",
    "            # Update counter and tqdm\n",
    "            comment_count += n_comments\n",
    "            #pbar.update(n_comments)\n",
    "\n",
    "        except:\n",
    "            # Sometimes my internet cuts off for a few minutes, or some other error happens.\n",
    "            # This try/except statement allows for the loop to continue.\n",
    "            # print(f\"Something went wrong at {datetime.now()} with submission {submission_id}\")\n",
    "            submission_errors.add(submission_id)\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Reached comment limit at {datetime.now()} with submission {submission_id}\")\n",
    "        print(f\"Collected {comment_count} comments\")\n",
    "        break\n",
    "        \n",
    "with open('raised_errors.txt','a') as f:\n",
    "    for i in submission_errors:\n",
    "        f.write(i)\n",
    "        f.write('\\n')        \n",
    "        \n",
    "print(f\"Finished at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "still-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108293\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(comment_count)\n",
    "print(submission_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-witch",
   "metadata": {},
   "source": [
    "## Find comments for submissions that raised errors or were in the first 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ruled-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raised_errors_pushshift.txt','r') as f:\n",
    "    errors = f.read()\n",
    "    \n",
    "errors = set(errors.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affiliated-british",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accepting-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"first700.txt\", \"r\") as f:\n",
    "    first = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "split-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ids.difference_update(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "enclosed-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ids.difference_update(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run 'Collect comments' again\n",
    "# for 701-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "valuable-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/241 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2022-02-14 06:21:51.398166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 241/241 [4:19:06<00:00, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at 2022-02-14 10:40:57.600850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting at {datetime.now()}\")\n",
    "comment_count = 0\n",
    "n_comment_attributes = len(comment_attributes)\n",
    "submission_errors = set()\n",
    "\n",
    "for submission_id in tqdm(submission_ids):\n",
    "\n",
    "    if comment_count < comment_limit:\n",
    "        try:\n",
    "            # Collect comments\n",
    "            comments_data = utils.get_comments_data(reddit, submission_id, comment_attributes=comment_attributes)\n",
    "\n",
    "            # Save the comments to the database\n",
    "            with conn:\n",
    "                n_comments = utils.add_rows(conn, 'comments', n_comment_attributes, comments_data)\n",
    "\n",
    "            # Update counter and tqdm\n",
    "            comment_count += n_comments\n",
    "            #pbar.update(n_comments)\n",
    "\n",
    "        except:\n",
    "            # Sometimes my internet cuts off for a few minutes, or some other error happens.\n",
    "            # This try/except statement allows for the loop to continue.\n",
    "            # print(f\"Something went wrong at {datetime.now()} with submission {submission_id}\")\n",
    "            submission_errors.add(submission_id)\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Reached comment limit at {datetime.now()} with submission {submission_id}\")\n",
    "        print(f\"Collected {comment_count} comments\")\n",
    "        break\n",
    "        \n",
    "with open('raised_errors.txt','a') as f:\n",
    "    for i in submission_errors:\n",
    "        f.write(i)\n",
    "        f.write('\\n')        \n",
    "        \n",
    "print(f\"Finished at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-papua",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-boxing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-scottish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-today",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-particular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitting-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_comments = utils.interact_with_db(conn, \"SELECT * FROM submissions where num_comments=0\", \"cur.fetchall()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "geological-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_set = set()\n",
    "for i in zero_comments:\n",
    "    zero_set.add(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electoral-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ids.difference_update(zero_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "found-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "legislative-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "careful-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_set.difference_update(submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "roman-zoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "meaning-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2pa6za', '372yx7', '37411h', '3u21u6'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "liquid-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('372yx7', \"Official Discussion: Marvel's The Avengers 2: Age Of Ultron\", 1, 1, 'http://www.reddit.com/r/movies/comments/372yx7/official_discussion_marvels_the_avengers_2_age_of/', 1432466525)]\n"
     ]
    }
   ],
   "source": [
    "print(utils.interact_with_db(conn, \"SELECT * FROM submissions where submission_id='372yx7'\", \"cur.fetchall()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "special-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(utils.interact_with_db(conn, \"SELECT * FROM comments where submission_id='372yx7'\", \"cur.fetchall()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-reflection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-petite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "listed-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967608,)\n"
     ]
    }
   ],
   "source": [
    "print(utils.interact_with_db(conn, \"SELECT COUNT(*) FROM comments\", \"cur.fetchone()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ambient-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1568971,)\n"
     ]
    }
   ],
   "source": [
    "print(utils.interact_with_db(conn, \"SELECT COUNT(*) FROM comments\", \"cur.fetchone()\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
