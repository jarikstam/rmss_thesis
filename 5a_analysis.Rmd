---
title: "Analysis"
author: "Jarik Stam"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r setup}
library(reticulate)
library(word2vec)
library(text2map)
library(Matrix)
library(data.table)
library(tidyverse)
library(lubridate)
library(lme4)
# library(robustlmm)
library(xtable)
library(stargazer)
library(ggcorrplot)
library(lattice)
library(vtable)

theme_set(cowplot::theme_minimal_hgrid())
Sys.setlocale("LC_TIME", "English")
```
```{python filenames}
from params import analysis_dataset, submissions_tmdb_file, count_file, binary_wv_file, wvdf_file, embedding_results_file
```
```{r params}
figures_path <- "figures"
output_path <- "output"

min_date <- ymd("2013-05-01")
max_date <- ymd("2022-02-01")
date_metoo <- ymd("2017-10-15")
date_floyd <- ymd("2020-6-2")
date_reign <- ymd("2015-1-15")

movements <- c("BLM", "MeToo", "OscarsSoWhite")
hashtag_names <- c("#OscarsSoWhite", "#MeToo", "#BlackLivesMatter")

# viz params ----
# colors
corr_colors <- rev(RColorBrewer::brewer.pal(3, "RdYlBu"))

tweets_color_scale <- viridis::viridis(n=3, option = "inferno")
names(tweets_color_scale) <- hashtag_names

# Linetypes
tweets_lines_scale <- c("1151", "1111", "solid")
names(tweets_lines_scale) <- hashtag_names

```
```{r functions}
plot_corr <- function(.data) {
  .data %>% 
    cor() %>% 
    ggcorrplot(lab=T, outline.col = "white",
             colors = corr_colors,
             show.legend = F, lab_size = 3,
             tl.cex = 10,
             show.diag = F)
}

save_plot <- function(plot, filename, width=10, height=6) {
  ggsave(filename, plot, "pdf", figures_path,
         width = width, height = height, units = "in", dpi = 1200)
  
  knitr::plot_crop(paste0(figures_path, "/", filename))
}

get_fixed <- function(model) {
  summary(model)["coefficients"][[1]] %>% 
    as_tibble(rownames = "Variable") %>% 
    rename("Coef." = Estimate,
           "S.E." = `Std. Error`,
           "T" = `t value`)
}

get_random <- function(model) {
  VarCorr(model) %>% 
    as_tibble() %>%
    select(!c(sdcor))
}

get_ll <- function(model) {
  logLik(model)[1]
}

get_models <- function(..., model_names=NULL, latex=F, filename=NULL, landscape=T) {
  
  if(length(list(...)) == 1) {
    
    df <- get_fixed(...)
    rdf <- get_random(...)
    ll <- get_ll(...)
    
  } else {
    
    df <- list(...) %>% 
      map(get_fixed) %>% 
      bind_rows(.id = "Model") %>%
      pivot_wider(
        names_from = "Model",
        values_from = 3:5,
        names_glue = "{Model}_{.value}"
      ) %>% 
      select(order(colnames(.))) %>%
      select(Variable, everything())
    
    rdf <- list(...) %>% 
      map(get_random) %>%
      bind_rows(.id = "Model") %>% 
      { if(latex) mutate(., zzy = NA, zzz = NA) else . } %>% 
      pivot_wider(
        names_from = "Model",
        values_from = 5:ncol(.),
        names_glue = "{Model}_{.value}"
      ) %>% 
      select(order(colnames(.))) %>%
      mutate(
        randomname = case_when(
          grp == "author" & var1 == "(Intercept)" & is.na(var2) ~ "sigsqhereInt/Commenter",
          grp == "author" & var1 != "(Intercept)" ~ str_c("sigsqhere", var1, "/Commenter"),
          grp == "author" & var1 == "(Intercept)" & !is.na(var2) ~ str_c("sigmahereInt:", var2, "/Commenter"),
          grp == "submission_id" & var1  == "(Intercept)" & is.na(var2) ~ "sigsqhereInt/Film Discussion",
          grp == "submission_id" & var1 != "(Intercept)" ~ str_c("sigsqhere", var1, "/Film Discussion"),
          grp == "submission_id" & var1 == "(Intercept)" & !is.na(var2) ~ str_c("sigmahereInt:", var2, "/Film Discussion"),
          grp == "Residual" ~ "sigsqhereInt/Comment",
          T ~ "grp names have changed"
        )
      ) %>% 
      mutate(across(where(is.character), ~ replace_na(.x, ""))) %>% 
      arrange(var2, var1, match(grp, c("Residual", "author", "submission_id"))) %>% 
      select(!all_of(c("grp", "var2", "var1"))) %>% 
      select(randomname, everything())
    
    ll <- list(...) %>% 
      map(get_ll)
  }
  if(latex){
    
    random <- rdf %>%
      xtable(digits = 3) %>% 
      print(
        include.rownames = F,
        include.colnames = F,
        print.results = F,
        booktabs = T,
        comment = F,
        only.contents = T
      ) %>% 
      str_replace_all("\\\\", "\\\\\\\\")
    
    nr_cols <- (ncol(df)-1)/3
    
    fixed <- df %>% 
      xtable(
        caption = "Random Effects Model for Discrimination Concept Engagement in Film Discusssion Comments",
        label = "Multilevel",
        digits = c(0, 0, rep(c(3, 2, 2), nr_cols)),
        align = c(rep("l", 2), rep("C", ncol(.)-1)),
      ) %>% 
      print(
        table.placement = "tb",
        caption.placement = "top",
        latex.environments = "threeparttable",
        tabular.environment = "tabular*",
        include.rownames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        width = "\\linewidth",
        comment = F,
        size = "\\sisetup{parse-numbers= false, mode=text}",
      ) %>% 
      str_replace(., "(?<=)toprule", str_replace_all(str_c("toprule\n", 
                                                           if_else(!is.null(model_names), 
                                                                   toString(map(model_names,
                                                                                ~ str_c(" & \\\\multicolumn{3}{c}{", 
                                                                                        .x, "}"))),
                                                                   toString(map(1:nr_cols,
                                                                        ~ str_c(" & \\\\multicolumn{3}{c}{Model ", 
                                                                                as.character(.x), "}")))),
                                                           
                                                           " \\\\\\\\\n",
                                                           toString(map(
                                                             1:nr_cols, ~ str_c("\\\\cmidrule(lr){", as.character(.x*2+.x-1), "-", as.character(.x*2+.x+1), "}"))),
                                                           "\n\\\\multicolumn{2}{l}{Fixed Effects} \\\\\\\\\n\\\\midrule"
      ),
      ", ", ""
      )
      ) %>% 
      str_replace(., "C{3,999}", str_c(" @{\\\\extracolsep{\\\\fill}} *{", str_length(str_extract(., "C{3,999}")), "}{@{}S[table-format=-1.3]@{}}")) %>% 
      str_replace_all("\\S*\\\\_Coef.", "{ Coef.}") %>%
      str_replace_all("\\S*\\\\_S.E.", "{ S.E.}") %>%
      str_replace_all("\\S*\\\\_T", "{ T}") %>%
      str_replace("(?<=)\\\\bottomrule\n",
                  str_c("\\\\midrule\n\\\\multicolumn{2}{l}{Random Effects} \\\\\\\\\n", random)) %>% 
      str_replace_all("\\\\verb\\|\\^\\|2", "$^{2}$") %>%
      str_replace_all("thread\\\\_age", "Film\\\\ Discussion\\\\ Creation") %>%
      str_replace_all("comment\\\\_age", "Comment Creation") %>%
      str_replace_all("politics\\\\_comments", "Politics Comments") %>%
      str_replace_all("sexism\\\\_keywords", "Sexism Keyword") %>%
      str_replace_all("racism\\\\_keywords", "Racism Keyword") %>%
      str_replace_all("(MeToo|BLM|OscarsSoWhite)", "\\\\#\\1 Tweets") %>%
      str_replace_all("Film Discussion", "Film\\\\ Discsussion") %>%
      str_replace_all("`", "") %>%
      str_replace_all("sigsqhere(.*?)(?= &)", "$\\\\sigma^{2}_{\\1}$") %>% 
      str_replace_all("sigmahere(.*?)(?= &)", "$\\\\sigma_{\\1}$") %>% 
      str_replace_all(":", "\\\\ X\\\\ ") %>%
      str_replace_all("X\\\\ Politics Comments", "X\\\\ Pol. Com.") %>% 
      str_replace("\\\\endgroup", "\\\\endgroup\n\\\\fnote{\\\\textit{Note.} N(comments) = 1,121,391. N(film discussions) = 1129. N(commenters) = 90,668.}"
              ) %>% 
      { if_else(landscape, str_c("\\begin{landscape}\n", ., "\\end{landscape}"), .) } %>% 
      { if_else(!is.null(filename), write(., str_c(output_path, "/", filename, ".tex")), cat(.)) }
    
  } else {
    return(list(df, rdf, ll))
  }
}

slope_model <- function(., slope_variable) {
  lmer(paste0("discrimination_centroid ~ thread_age + `thread_age^2` + comment_age + politics_comments + MeToo + BLM + OscarsSoWhite + sexism_keywords + racism_keywords + (1|submission_id) + (1+", slope_variable, "|author)"),
       data = ., REML = FALSE, 
       control = lmerControl(optimizer ="Nelder_Mead")
  )
}

```
```{r data}
# Filtering comments ----
# AutoModerator is a bot used by Reddit moderators for automized moderation
# [deleted] and None are unknown authors (mostly) because of deleted accounts whose comments remain, meaning I can't test for within-author change
comments <- fread(py$analysis_dataset, data.table = FALSE)

comments <- comments %>%
  as_tibble() %>% 
  filter(!author %in% c("AutoModerator", "[deleted]", "None"))

# Removing days from before min_date because before that data is very sparse
# From may 2013 there is at least on film discussion thread per month
# And from after Jan 2022 because data might be incomplete
# (i.e., those threads were still active at time of collection)
# This only removes ~ 10000 comments
comments <- comments %>%
  filter(Date >= min_date,
         Date < max_date)

comments <- comments %>% 
  select(!created)

comments <- comments %>% 
  group_by(submission_id) %>% 
  mutate(Date = date(Date),
         thread_date = min(Date),
         thread_age = interval(min_date, min(Date)) / years(1)) %>% 
  ungroup() %>% 
  mutate(comment_age = interval(thread_date, Date) / weeks(1))

# For a long time, one wouldn't be able to comment in submissions older than 180 days
# This was disabled 15-okt-2021, meaning there are now a few comments way older than 180 days (i.e., 3000 days), I think these comments are outliers
# See lines 291-292 from https://github.com/reddit-archive/reddit/commit/0ae8f2fb96cd39a01e8bff2cb4b1829b7bdbd0a8#diff-f28c2f2d93f455301ef0180437b545fdR291

comments <- comments %>% 
  filter(comment_age <= 180)

# Exploration shows that there are many short comments with undeserved high scores on the vars.
# E.g. 1-word comments like "yes" and "same" score over 2 sd's above 0.
comments <- comments %>% 
  filter(str_count(tokenized_body, "\\w+") >= 10)

# Removing authors who haven't commented in at least 2 different submissions, because they add a lot of calculation without adding much interesting variation
comments <- comments %>% 
  group_by(author) %>% 
  filter(n_distinct(submission_id) > 1) %>% 
  # Doing log(x+1) because that's what I do with other logged vars
  mutate(movies_comments = log(n()+1)) %>% 
  ungroup()

# Mutating variables ----
comments <- comments %>% 
  mutate(
    # Mutating to log(x+1) for several vars because they minimum zero and very long righthand tails
    across(all_of(c(movements, "politics_comments")), ~ log(.x+1)),
    # Standardizing score to make its range more similar to that of other vars
    # across(all_of(c("score", "vote_count")), ~ scale(.x)[,1]),
    # Creating a dummy because the var isn't very continuous
    across(ends_with("keywords"), ~ if_else(.x == 0, 0, 1)),
    "thread_age^2" = thread_age^2,
    film_title = str_replace_all(film_title, "&amp;", "&")
    )

# Other data ----
tmdb <- read_delim(py$submissions_tmdb_file, delim = ";")
genres <- tmdb %>% select(`Science Fiction`:Documentary) %>% colnames()

comments <- tmdb %>% 
  select(all_of(c("submission_id", genres))) %>% 
  right_join(comments)

tweets <- read_csv(py$count_file)

# model <- read.word2vec(file = py$binary_wv_file, normalize = TRUE)
```
```{r cmd}
# https://cran.r-project.org/web/packages/text2map/vignettes/CMDist-concept-movers-distance.html
# Options: single words, compound words, semantic directions, centroids.

wv <- read_csv(py$wvdf_file) %>% 
  column_to_rownames("...1") %>% 
  data.matrix(rownames.force = TRUE)

dtm <- comments %>% 
  dtm_builder(tokenized_body, comment_id)

concept_words <- c("sexism", "racism", "discrimination")
sexism_words <- c("sexism", "metoo", "sexist", "sexual_harassment", "misogyny", "patriarchy",
                  "sexualization", "sjws", "rape_culture", "toxic_masculinity")
racism_words <- c("racism", "blm","racist", "racists", "racial", "segregation", "systemic_racism",
                  "police_brutality", "white_supremacy",
                  "institutional_racism", "race_relations", "bigoted")
discrimination_words <- c("discrimination", sexism_words, racism_words)

# predict(model, newdata = "racism", type = "nearest", top_n = 10)

sexism_centroid <- get_centroid(sexism_words, wv)
racism_centroid <- get_centroid(racism_words, wv)
discrimination_centroid <- get_centroid(discrimination_words, wv)

doc_closeness <- CMDist(dtm = dtm, cw = concept_words, cv = sexism_centroid, wv = wv)
racism_closeness <- CMDist(dtm = dtm, cv = racism_centroid, wv = wv)
discrimination_closeness <- CMDist(dtm = dtm, cv = discrimination_centroid, wv = wv)

doc_closeness <- doc_closeness %>%
  rename_with(~ str_c(.x, "_cmd"),
              all_of(concept_words)
  )

comments <- comments %>%
  left_join(doc_closeness, by=c("comment_id" = "doc_id")) %>%
  left_join(racism_closeness, by=c("comment_id" = "doc_id")) %>%
  left_join(discrimination_closeness, by=c("comment_id" = "doc_id"))

rm(dtm, doc_closeness, racism_closeness, discrimination_closeness, wv)
```
```{r descriptives}
# disc per submission ----
submissions <- comments %>% 
  group_by(submission_id, film_title) %>% 
  summarise(
    across(where(is.numeric), ~ mean(.x))
  ) %>% 
  ungroup() %>% 
  mutate(Keywords = case_when(
    racism_keywords == 0 & sexism_keywords == 0 ~ "Neither",
    racism_keywords == 1 & sexism_keywords == 0 ~ "Racism",
    racism_keywords == 0 & sexism_keywords == 1 ~ "Sexism",
    racism_keywords == 1 & sexism_keywords == 1 ~ "Both",
    T ~ NA_character_
  ))

plot_disc_mean <- submissions %>% 
  mutate(label = if_else(discrimination_centroid > 1 | discrimination_centroid < -0.5, film_title, NA_character_)) %>% 
  mutate(thread_date = date(min_date+dyears(thread_age))) %>% 
  arrange(match(Keywords, c("Neither", "Racism", "Sexism", "Both"))) %>% 
  ggplot(aes(thread_date, discrimination_centroid, 
             color = fct_inorder(Keywords), shape = fct_inorder(Keywords),
             label = label
  )) +
  geom_point(size = 3) +
  ggrepel::geom_text_repel(color="black",
                           na.rm=T, show.legend = F,
                           # direction = "y", nudge_y = .01
  ) +
  scale_color_viridis_d(direction = -1) +
  scale_x_date(breaks = seq(from = min_date, to = max_date, by = "2 months"),
               date_labels = "%b '%y",
               expand = expansion(mult = c(0.005, 0.005))
               ) +
  labs(
    x = element_blank(),
    y = "Mean Discrimination Engagement",
    color = "Keywords:",
    shape = "Keywords:",
  ) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

plot_disc_mean

# disc distribution ----
thread_selection <- comments %>% 
  group_by(submission_id) %>% 
  summarise(mn = mean(discrimination_centroid)) %>% 
  arrange(desc(mn)) %>% 
  filter(row_number() %% 38 == 1) %>% 
  pull(submission_id)

plot_distr <- comments %>% 
  filter(submission_id %in% thread_selection) %>% 
  ggplot(aes(fct_reorder(film_title, discrimination_centroid), discrimination_centroid, 
             fill=fct_reorder(film_title, discrimination_centroid),
             color=fct_reorder(film_title, discrimination_centroid))) +
  geom_violin() +
  scale_y_continuous(expand = expansion(mult = c(0.02,0))) +
  scale_fill_ordinal() +
  scale_color_ordinal() +
  labs(
    x = element_blank(),
    y = "Discrimination Engagement"
  ) +
  theme(
    legend.position = "none"
  ) +
  coord_flip()

comments %>% 
  select(var_selection) %>% 
  as.data.frame() %>% 
  stargazer(., nobs = FALSE, type = "text")

# Correlations ----
plot_correlations <-  comments %>% 
  select(all_of(var_selection)) %>%
  rename_with(
      ~ case_when(
        .x == "MeToo" ~ "#MeToo Tweets",
        .x == "BLM" ~ "#BlackLivesMatter Tweets",
        .x == "OscarsSoWhite" ~ "#OscarsSoWhite Tweets",
        .x == "sexism_keywords" ~ "Sexism Keyword",
        .x == "racism_keywords" ~ "Racism Keyword",
        .x == "politics_comments" ~ "Politics Comments",
        .x == "thread_age" ~ "Film Discussion Creation",
        .x == "thread_age^2" ~ "Film Discussion Creation^{2}",
        .x == "comment_age" ~ "Comment Creation",
        .x == "discrimination_centroid" ~ "Discrimination Engagement",
        T ~ .x
      )
    ) %>% 
  plot_corr()

plot_correlations

plot_concepts <-  comments %>% 
  select(ends_with("_cmd") | ends_with("_centroid")) %>% 
  plot_corr()

plot_concepts

# Monthly Tweets ----
plot_monthly_tweets <- tweets %>% 
  filter(Date >= min_date,
         Date < max_date) %>% 
  group_by(Date = floor_date(Date, "month")) %>% 
  summarise(across(all_of(movements), sum)) %>% 
  reshape2::melt(id.vars="Date", variable.name = "Movement", value.name = "Tweets") %>%
  mutate(Movement = as.character(Movement)) %>% 
  arrange(Movement) %>% 
  mutate(label = case_when(
    (Date == floor_date(date_metoo, "month")) & (Movement == "MeToo") ~ "Alyssa Milano\nTweet",
    (Date == floor_date(date_floyd, "month")) & (Movement == "BLM") ~ "George Floyd Protests",
    (Date == floor_date(date_reign, "month")) & (Movement == "OscarsSoWhite") ~ "April Reign\nTweet",
    #(Date == min(Date)) & (Movement == "MeToo") ~ "#MeToo",
    #(Date == min(Date)) & (Movement == "BLM") ~ "#BLM",
    #(Date == min(Date)) & (Movement == "OscarsSoWhite") ~ "#OscarsSoWhite",
    T ~ NA_character_
  )) %>% 
  mutate(Movement = if_else(Movement == "BLM", "BlackLivesMatter", Movement),
         Movement = str_c("#", Movement)) %>%
  ggplot(aes(Date, Tweets, color=Movement, linetype=Movement, label=label)) +
  geom_line(size=2) +
  scale_x_date(date_breaks = "2 months", date_labels = "%b '%y",
               expand = expansion(mult = c(0, 0))) +
  scale_y_log10(
                limits = c(10,10^8),
                breaks = scales::log_breaks(8),
                labels = scales::comma,
                expand = expansion(mult = c(0, 0.02))
                ) +
  ggrepel::geom_text_repel(color="black",
                           na.rm=T, show.legend = F,
                         direction = "y", nudge_y = .01
           ) +
  #scale_color_brewer(palette = "Set3") +
  scale_color_manual(values=tweets_color_scale) +
  scale_linetype_manual(values=tweets_lines_scale) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position = "top") +
  labs(
    color = "Movement:",
    linetype = "Movement:",
    y = "Tweets",
    x = element_blank()
    #title = "Social Movements' Tweets per Month"
  ) +
  guides(
    linetype=guide_legend(keywidth = 1.8, keyheight = 1),
    color=guide_legend(keywidth = 1.8, keyheight = 1))

plot_monthly_tweets

# tmdb ----
tmdb %>% 
  select(where(is.numeric)) %>%
  select(sexism_keywords, racism_keywords, everything()) %>% 
  plot_corr()

tmdb %>% 
  select(sexism_keywords, racism_keywords, film_title) %>% 
  mutate(x = n()) %>% 
  group_by(racism_keywords) %>% 
  summarise(fre = n()/x) %>% 
  tally()

tmdb %>% 
  select(sexism_keywords, racism_keywords, film_title) %>% 
  arrange(desc(racism_keywords))

tmdb %>% 
  select(sexism_keywords, racism_keywords, film_title) %>% 
  reshape2::melt(id.vars = "film_title", variable.name = "Keyword") %>% 
  ggplot(aes(value, color = Keyword, fill = Keyword)) +
  geom_bar(aes(y=..prop..), position = "dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), n.breaks = 10)

tmdb %>%
  filter(date >= min_date,
         date < max_date) %>% 
  mutate(across(ends_with("_keywords"), ~ if_else(.x > 0, 1, 0)),
         date = date(date)
         ) %>% 
  rename_with(.fn = ~ str_to_title(str_remove(.x, "_keywords"))) %>% 
  reshape2::melt(id.vars="Date", measure.vars = c("Sexism", "Racism"), variable.name = "Disc", value.name = "Keyword") %>%
  # group_by(Date = floor_date(Date, unit = "month"), Disc) %>% 
  # summarise(Keyword = mean(Keyword)) %>% 
  ggplot(aes(Date, Keyword, color=Disc, fill=Disc)) +
  geom_smooth(method = "loess", alpha=.2) +
  scale_x_date(date_breaks = "2 months", date_labels = "%b '%y",
               expand = expansion(mult = c(0, 0))) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0))) +
  scale_color_viridis_d() +
  scale_fill_viridis_d() +
  scale_linetype_manual(values=c("sold", "1111")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position = "top") +
  labs(
    color = element_blank(),
    fill = element_blank(),
    linetype = element_blank(),
    y = "Film Has Keyword",
    x = element_blank()
    #title = "Social Movements' Tweets per Month"
  ) +
  guides(
    linetype=guide_legend(keywidth = 1.8, keyheight = 1),
    color=guide_legend(keywidth = 1.8, keyheight = 1))
# PEW ----
pew_surveys <- c("Autumn 2016", "Autumn 2018", "Spring 2019", "Autumn 2019", "Spring 2021")
pew_labs <- list(bquote(atop("Autumn", ~2016^a)),
                 bquote(atop("Autumn", ~2018^b)),
                 bquote(atop("Spring", ~2019^c)),
                 bquote(atop("Autumn", ~2019^d)),
                 bquote(atop("Spring", ~2021^e))
)

names(pew_labs) <- pew_surveys

plot_pew <- tibble(
  Survey = pew_surveys,
  Sexism_big = c(.21, .34, .26, .26, .23),
  Sexism_mod = c(.36, .35, .40, .35, .36),
  Sexism_small = c(.34,.24,.28,.29,.30),
  Sexism_not = c(.08,.07,.05,.09,.10),
  Racism_big = c(.36,.46,.4,.43,.45),
  Racism_mod = c(.41,.32,.37,.31,.27),
  Racism_small = c(.2,.18,.19,.21,.2),
  Racism_not = c(.03,.04,.03,.04,.07)
) %>% 
  pivot_longer(!Survey, names_to = c("Disc", "Level"), names_sep = "_", values_to = "Percent") %>% 
  arrange(match(Survey, pew_surveys), 
          match(Level, c("not", "small", "mod", "big"))) %>% 
  ggplot(aes(fct_inorder(Survey), Percent, fill = fct_inorder(Level))) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Disc, nrow = 1) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1),
                     expand = expansion(mult = c(0,.09))) +
  scale_x_discrete(expand = expansion(mult = c(0,0)),
                   labels = pew_labs) +
  scale_fill_brewer(
    labels = c("Not a problem at all",
               "A small problem",
               "A moderately big problem",
               "A very big problem"),
    palette = "BuGn"
  ) +
  labs(
    fill = element_blank(),
    x = element_blank(),
    y = element_blank()
  ) +
  theme(
    legend.position = "top",
    strip.text = element_text(size = 16),
    panel.spacing = unit(2, "lines")
  )

plot_pew
```
```{r multilevel}
# step 1: Intercept only model ----
m1 <- comments %>% 
  lmer(
    discrimination_centroid ~ 
      (1|submission_id) + (1|author), ., REML = FALSE,
    control = lmerControl(optimizer ="Nelder_Mead")
       )

# step 3: Author and submission level variables ----
m3 <- comments %>%
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments + 
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

m3a <- comments %>%
  lmer(discrimination_centroid ~ 
         thread_age +
         (1|submission_id) + (1|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

m3b <- comments %>%
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         (1|submission_id) + (1|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )
# step 4: Random slope ----
m4 <- comments %>%
  slope_model("thread_age")

m4a <- comments %>%
  slope_model("MeToo") 

m4b <- comments %>% 
  slope_model("BLM")

m4c <- comments %>% 
  slope_model("OscarsSoWhite")

m4d <- comments %>% 
  slope_model("comment_age")

m4e <- comments %>% 
  slope_model("sexism_keywords")

m4f <- comments %>% 
  slope_model("racism_keywords")

m4g <- comments %>%
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments + 
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1+comment_age|submission_id) + (1|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

m4gb <- comments %>%
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments + 
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1+ politics_comments |submission_id) + (1|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

slope_models <- list(
  "Film Disc. Creation/Commenter" = m4,
  "#MeToo/Commenter" = m4a,
  "#BLM/Commenter" = m4b,
  "#OscarsSoWhite/Commenter" = m4c,
  "Comment Creation/Commenter" = m4d,
  "Sexism Keyword/Commenter" = m4e,
  "Racism Keyword/Commenter" = m4f,
  "Comment Creation/Film Discussion" = m4g,
  "Politics Comments/Film Discussion" = m4gb
)

slope_improvements <- slope_models %>% 
  map(~ anova(m3, .x)) %>% 
  bind_rows(.id = "Model") %>% 
  as_tibble() %>% 
  filter((row_number() %% 2 != 1) | (row_number() == 1)) %>% 
  mutate(
    Model = if_else(row_number() == 1, "Variance Component Model", Model)
  )

m4h <- comments %>% # Failed to converge in 10000 evaluations
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments + 
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1 + thread_age + MeToo + BLM + OscarsSoWhite + comment_age + sexism_keywords + racism_keywords |author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

m4i <- comments %>% # Failed to converge in 10000 evaluations
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments + 
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1 + thread_age + MeToo + OscarsSoWhite + racism_keywords |author), 
       data = ., REML = FALSE, control = lmerControl(optimizer ="Nelder_Mead")
       )

m4j <- comments %>% # singular fit. Perfect correlation between the slope of thread age and author intercept
  lmer(discrimination_centroid ~ 
         thread_age + `thread_age^2` +
         comment_age +
         politics_comments +
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1 + thread_age + racism_keywords | author), 
       data = ., REML = FALSE, control = lmerControl(optimizer ="Nelder_Mead")
       )

# step 5: cross-level interactions ----
m5 <- comments %>%
  lmer(discrimination_centroid ~ 
         (thread_age + `thread_age^2`) * politics_comments +
         comment_age +
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1+thread_age|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
       )

m5_transformed <- comments %>% 
  mutate(discrimination_centroid = log(discrimination_centroid+max(discrimination_centroid)+1)) %>% 
  lmer(discrimination_centroid ~ 
         (thread_age + `thread_age^2`) * politics_comments +
         comment_age +
         MeToo + BLM + OscarsSoWhite +
         sexism_keywords + racism_keywords +
         (1|submission_id) + (1+thread_age|author), 
       data = ., REML = FALSE,
       control = lmerControl(optimizer ="Nelder_Mead")
  )

# Output ----
stargazer(m1, m3b, m3, m4, m5, type = "text")
get_models(m1, m3b, m3, m4, m5)
anova(m1, m2, m3b, m3, m4)
```
```{r diagnostics}
(plot_m1_qq <- qqmath(m1))

res_m1 <- resid(m1)
ranef_m1 <- ranef(m1, condVar=F)

(plot_m1_qq_level2 <- qqmath(ranef_m1))

(plot_m1_srvf <- plot(m1))

```
```{r exporting}
# figures ----
save_plot(plot_monthly_tweets, "monthly_tweets.pdf")
save_plot(plot_concept, "concept_correlations.pdf", 8, 6)
save_plot(plot_correlations, "correlations.pdf", 8, 6)
save_plot(plot_disc_mean, "thread_discrimination.pdf")
save_plot(plot_distr, "disc_distribution.pdf")
save_plot(plot_pew, "pew.pdf")

png(file = paste0(figures_path, "/qq_m1_l1.png"))
plot_m1_qq
dev.off()

png(file = paste0(figures_path, "/qq_m1_author.png"))
plot_m1_qq_level2$author
dev.off()

png(file = paste0(figures_path, "/qq_m1_sub.png"))
plot_m1_qq_level2$submission_id
dev.off()

png(file = paste0(figures_path, "/srvf_m1_l1.png"))
plot_m1_srvf
dev.off()

# results ----
get_models(m1, m3b, m3, m4, m5, model_names = c("Intercept Only", "Film Disc. Creation", "Full VCM","Random Slope", "Interaction"), latex = T, filename = "multilevel")

slope_improvements %>% 
  xtable(
        caption = "Likelihood-Ratio Test for Random Slope Models Improvement over Variance Component Model",
        label = "tab:Slope",
        digits = c(rep(0, ncol(.)), 3),
        align = c("l", "l", rep("C", ncol(.)-1))
      ) %>% 
      print(
        table.placement = "tb",
        caption.placement = "top",
        latex.environments = "threeparttable",
        tabular.environment = "tabular",
        include.rownames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        # width = "\\linewidth",
        comment = F,
        size = "\\sisetup{parse-numbers= false, mode=text}"
      ) %>% 
  str_replace("& npar & AIC & BIC & logLik & deviance & Chisq & Df & Pr\\(\\$\\>\\$Chisq\\)",
              "& {npar} & {AIC} & {BIC} & {logLik} & {deviance} & {$\\\\chi^2$} & {Df} & {p}") %>% 
  str_replace_all("0\\.000", "<.001") %>% 
  str_replace_all("0\\.", ".") %>% 
  str_replace("C{3,999}", " @{}S[table-format=2.0]@{} *{4}{@{}S[table-format=-7.0]@{}} @{ }S[table-format=4.0]@{} @{ }S[table-format=2.0]@{} @{ }S[table-format=<.3]@{}"
              ) %>% 
  # cat()
  write(., paste0(output_path, "/slope.tex"))

anova(m1, m3a, m3b, m3, m4, m5) %>% 
  as_tibble(rownames = "Model") %>% 
  mutate(Model = case_when(
    Model == "m1" ~ "Intercept Only",
    Model == "m3a" ~ "+ Linear Effect Thread Creation",
    Model == "m3b" ~ "+ Quadratic Effect Thread Creation",
    Model == "m3" ~ "Full Variance Component Model",
    Model == "m4" ~ "+ Slope for Creation/Commenter",
    Model == "m5" ~ "+ Film Disc. Creation X Pol. Comments",
    T ~ Model
  )) %>% 
  xtable(
        caption = "Likelihood-Ratio Test for Model Improvement over Previous Model",
        label = "tab:Anova",
        digits = c(rep(0, ncol(.)), 3),
        align = c("l", "l", rep("C", ncol(.)-1))
      ) %>% 
      print(
        table.placement = "tb",
        caption.placement = "top",
        latex.environments = "threeparttable",
        tabular.environment = "tabular",
        include.rownames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        # width = "\\linewidth",
        comment = F,
        size = "\\sisetup{parse-numbers= false, mode=text}"
      ) %>% 
  str_replace("& npar & AIC & BIC & logLik & deviance & Chisq & Df & Pr\\(\\$\\>\\$Chisq\\)",
              "& {npar} & {AIC} & {BIC} & {logLik} & {deviance} & {$\\\\chi^2$} & {Df} & {p}") %>% 
  str_replace_all("0\\.000", "<.001") %>% 
  str_replace_all("0\\.", ".") %>% 
  str_replace("C{3,999}", " @{}S[table-format=2.0]@{} *{4}{@{}S[table-format=-7.0]@{}} @{}S[table-format=4.0]@{} @{ }S[table-format=2.0]@{} @{ }S[table-format=<.3]@{}"
              ) %>% 
  # cat()
  write(., paste0(output_path, "/anova.tex"))

# other tables ----
comments %>% 
  select(ends_with("_cmd") | ends_with("_centroid")) %>%
  colnames() %>% 
  as_tibble_col(column_name = "Concept") %>% 
  mutate(Words = case_when(
    endsWith(Concept, "_cmd") ~ str_replace(Concept, "_cmd", ""),
    startsWith(Concept, "sexism") ~ toString(sexism_words),
    startsWith(Concept, "racism") ~ toString(racism_words),
    startsWith(Concept, "discrimination") ~ toString(discrimination_words),
    T ~ NA_character_
  ),
  Concept = str_to_title(str_replace(Concept, "_", " ")),
  Concept = str_replace(Concept, "Cmd", "CMD")
  ) %>% 
  xtable(
        caption = "Words Used for Concept Mover's Distance (CMD)",
        label = "tab:CmdConcept",
        align = c(rep("l", 2), rep("L", ncol(.)-1)),
      ) %>% 
      print(
        table.placement = "htb",
        caption.placement = "top",
        # latex.environments = "threeparttable",
        latex.environments = NULL,
        tabular.environment = "tabulary",
        include.rownames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        width = "\\linewidth",
        comment = F,
      ) %>% 
  write(., paste0(output_path, "/concept_words.tex"))

comments %>% 
  select(var_selection) %>% 
  st(out="return",
     summ=c("mean(x)", "sd(x)", "min(x)", "max(x)"),
     digits = 2, fixed.digits = F,
     ) %>% 
  as_tibble() %>% 
  xtable(
        caption = "Descriptive Statistics",
        label = "tab:DescStat",
        align = c(rep("l", 2), rep("C", ncol(.)-1))
      ) %>% 
      print(
        table.placement = "htb",
        caption.placement = "top",
        latex.environments = "threeparttable",
        tabular.environment = "tabular",
        include.rownames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        # width = "\\linewidth",
        comment = F,
        size = "\\sisetup{parse-numbers= false, mode=text}"
      ) %>% 
  str_replace(., "C{3,999}", str_c(" *{", str_length(str_extract(., "C{3,999}")), "}{@{ }S[table-format=-1.2]@{ }}")) %>%
  str_replace("Variable & Mean & Sd & Min & Max", " & {Mean} & {S.D.} & {Min} & {Max}") %>% 
  str_replace_all("thread\\\\_age", "Film Discussion Creation") %>%
  str_replace_all("comment\\\\_age", "Comment Creation") %>%
  str_replace_all("politics\\\\_comments", "Politics Comments") %>%
  str_replace_all("sexism\\\\_keywords", "Sexism Keyword") %>%
  str_replace_all("racism\\\\_keywords", "Racism Keyword") %>%
  str_replace_all("(MeToo|BLM|OscarsSoWhite)", "\\\\#\\1 Tweets") %>%
  str_replace_all("discrimination\\\\_centroid", "Discrimination Concept Engagement") %>%
  str_replace_all("`", "") %>%
  str_replace("end\\{tabular\\}", "end{tabular}\n\\\\fnote{\\\\textit{Note.} N(comments) = 1,121,391.}"
  ) %>% 
  write(., paste0(output_path, "/desc_stats.tex"))
  # cat()

read_csv(py$embedding_results_file) %>% 
  select(!Wordsim) %>% 
  rename("Wordsim" = "Sp_corr") %>%
  xtable::xtable(
    caption = "Word Embedding Model Comparison",
    label = "Embedding",
    align = rep("C", ncol(.)+1),
    digits = c(0,0,0,3,3)
  ) %>% 
  print(
    table.placement = "tb",
    caption.placement = "top",
    latex.environments = "threeparttable",
    tabular.environment = "tabulary",
    include.rownames = F,
    #math.style.negative = T,
    print.results = F,
    booktabs = T,
    width = "\\linewidth",
    comment = F
  ) %>% 
  str_replace(., "Google", "\\\\% Correct Google Analogies$^{a}$") %>% 
  str_replace(., "Wordsim", "WordSim-353 Spearman's $\\\\rho^{b}$") %>% 
  str_replace(., "25 & 300 & 0.459 & 0.568", "\\\\textbf{25} & \\\\textbf{300} & \\\\textbf{0.459} & \\\\textbf{0.568}") %>% 
  str_replace(., "end\\{tabulary\\}", "end{tabulary}\n\\\\fnote{\\\\textit{Note.} Model trained using Gensim's Word2Vec. Chosen model in bold.}\n\\\\fnote{$^{a} =$ Google Analogy Test \\\\parencite{Mikolov2013}.}\n\\\\fnote{$^{b} =$ WordSimilarity-353 \\\\parencite{Finkelstein2001}.}") %>% 
  write(., paste0(output_path, "/embeddingResults.tex"))
```
```{r graveyard} 
# functions ----
se <- function(x) sd(x)/sqrt(length(x))

lm_fitted <- function(.data, formula) {
  if (dplyr::is_grouped_df(.data)) {
      return(dplyr::do(.data, lm_fitted(., formula)))
    }
  model <- lm(formula=formula, data=.data)
  pred_vals = dplyr::tibble(
    fit = predict(model),
    se = predict(model, se.fit=T)$se.fit
  )
  .data <- bind_cols(.data, pred_vals)
  .data
}

get_random <- function(model) {
  VarCorr(model) %>% 
    as_tibble() %>%
    mutate(icc = vcov/sum(vcov),
           icc = if_else(grp=="Residual", NaN, icc)) %>% 
    select(!c(var2, sdcor))
}

# get_fixed <- function(model) {
#   summary(model)$coefficients %>% 
#     as_tibble(rownames = "Variable") %>% 
#     rename("Coef." = Estimate,
#            "S.E." = `Std. Error`,
#            "T" = `t value`)
# }

get_sum <- function(model) {
  fm <- get_fixed(model)
  rm <- get_random(model)
  ll <- logLik(model)[1]
  return(list(fm, rm, ll))
} 
# unique user ids ----

# There are many usernames "None", which are from deleted accounts. This makes them all unique
# If doing this, need to do something about politics_comments
comments <- comments %>% 
  mutate(
    author = if_else(
      author %in% c("[deleted]", "None"), 
      str_c("#", as.character(row_number())), # Hashtags are illegal characters in usernames, thus now these names are assured to be unique.
      author
    ),
    # Replacing politics_comments with the mean of the other rows
    politics_comments = if_else(str_detect(author, "#"), NaN, politics_comments),
    politics_comments = if_else(is.na(politics_comments), mean(politics_comments, na.rm=T), politics_comments)
  )

# Explore data ----
comments %>%
  select(date, submission_id) %>% 
  group_by(submission_id) %>% 
  summarise(days_since_sub = median(date - date_crea )) %>% 
  filter(days_since_sub < 30) %>% 
  ggplot(aes(days_since_sub)) +
  stat_ecdf() +
  geom_vline(xintercept = 7, linetype=2) +
  scale_x_continuous(breaks = seq(0, 30, 1), limits = c(0,30), expand = c(0,0)) +
  labs(
    title = "The median number of days after a submission for comments to be posted ",
    x = "Number of days since submission",
    y = "Cumulative % of submissions"
  )

# Number of comments after creation date ----
# plot_comment_age <- comments %>% 
comments %>% 
  filter(comment_age <= 30) %>% 
  ggplot(aes(comment_age)) +
  geom_bar(aes(y=..prop..)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 2),
                     expand = expansion(mult = c(0,0.02))) +
  scale_x_continuous(expand = expansion(mult = c(0,0))) +
  labs(
    x = "Days Between Thread Creation and Comment Creation",
    y = "Proportion of Comments"
  )

# plot_comment_age

# Number of discussion threads per month ----
comments %>% 
  group_by(submission_id, film_title) %>% 
  summarise(Date = min(Date)) %>%
  mutate(Date = floor_date(Date, "month")) %>% 
  ggplot(aes(Date)) + 
  geom_bar() + 
  scale_x_date(
    date_breaks = "2 months", date_labels = "%b '%y", 
    expand = expansion(mult = c(0, 0))) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# Descriptive statistics ----
var_selection <- comments %>% 
  select(all_of(c("thread_age", "comment_age", "politics_comments", movements, "sexism_keywords", "racism_keywords")) | ends_with("_cmd") | ends_with("_centroid")) %>% 
  colnames()
# Linear models ----
lin <- comments %>% 
  filter(Date >= ymd("2014-01-01"),
         Date < ymd("2022-01-01")) %>%
  lm(sexism_centroid ~ MeToo_before * MeToo, data = .)

summary(lin)

lin %>% 
  sjPlot::plot_model(type = "int", mdrt.values = "meansd")

lin %>% 
  broom::augment() %>% 
  arrange(.fitted) %>% 
  head()

lm_colors <- c(
  "Actual Means" = "green",
  "Loess Smoothed Actual Means" = "red",
  "Predicted Means" = "black",
  "Loess Smoothed Predicted Means" = "blue")

comments %>% 
  filter(Date >= ymd("2014-01-01"),
         Date < ymd("2022-01-01")) %>% 
  lm_fitted(sexism_centroid ~ MeToo_before * MeToo) %>%
  group_by(floor_date(Date, unit = "month")) %>% 
  summarise(fit = mean(fit),
            value = mean(sexism_centroid),
            Date = min(Date)) %>% 
  mutate(label = case_when(
    abs(Date - date_metoo) == min(abs(Date - date_metoo)) ~ "Alyssa Milano\nTweet",
    T ~ NA_character_)) %>% 
  group_by(label) %>% 
  mutate(label = if_else(!duplicated(label), label, NA_character_)) %>% 
  ungroup() %>% 
  ggplot(aes(Date, fit, label=label)) +
  # geom_line(aes(y=value, color = "Actual Means")) +
  geom_smooth(aes(y=value, color = "Loess Smoothed Actual Means"), method = "loess",se=F) +
  geom_line(aes(color = "Predicted Means")) +
  geom_smooth(aes(color = "Loess Smoothed Predicted Means"), method = "loess", se=F) +
  # scale_y_continuous(limits = c(-0.05, 0.05)) +
  scale_x_date(date_breaks = "2 months", date_labels = "%b '%y",
               expand = expansion(mult = c(0, 0))) +
  scale_color_manual(values = lm_colors) +
  ggrepel::geom_text_repel(color="black",
                           na.rm=T, show.legend = F,
                         # direction = "y", 
                         nudge_y = .02,
                         min.segment.length = Inf
           ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position = "top",
        legend.title = element_blank()) +
  labs(title = "Predicted Values of Sexism-Related Comments Over Time",
       subtitle = "Formula: CMD from sexism ~ log( #MeToo tweets) * cumulative frequency of #MeToo tweets",
       x = element_blank(),
       y = "Predicted Value")

comments %>% 
  group_by(submission_id) %>% 
  summarise(sexism_centroid = mean(sexism_centroid),
            sexism_keywords = min(sexism_keywords)) %>% 
  group_by(sexism_keywords) %>% 
  summarise(sexism_centroid = mean(sexism_centroid)) %>% 
  ggplot(aes(sexism_keywords, sexism_centroid)) +
  geom_bar(stat = "identity")

# Effect of time ----
comments %>% 
  ggplot(aes(Date, discrimination_centroid)) +
  geom_smooth(method="lm", se=T, color="red", fill="red") +
  geom_smooth(method="lm", formula = "y ~ poly(x, 2)", se=T, color="yellow", fill="yellow") +
  geom_smooth(method="lm", formula = "y ~ poly(x, 3)", se=F, color="green") +
  geom_smooth(method="lm", formula = "y ~ poly(x, 4)", se=F, color="blue") +
  geom_smooth(method="lm", formula = "y ~ poly(x, 5)", se=T, color="purple", fill="purple") +
  # scale_x_date(
  #   date_breaks = "1 years", date_labels = "%Y", 
  #   expand = expansion(mult = c(0, 0))) + 
    scale_x_date(date_breaks = "2 months", date_labels = "%b '%y",
               expand = expansion(mult = c(0, 0))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Grouped by date ----
daily <- comments %>% 
  group_by(date = floor_date(date, "day")) %>%
  summarise(date = min(date),
            across(all_of(centroid_words), list(mean = mean, se = se))) %>% 
  pivot_longer(
    !date,
    names_to = c("keyword", ".value"),
    names_sep = "_"
  ) %>% 
  mutate(keyword = case_when(keyword=="blm" ~ "BLM",
                             keyword=="metoo" ~ "MeToo",
                             T ~ str_to_title(keyword))) %>% 
  left_join(twitter, by=c("date" = "Date", "keyword" = "movement"))

daily %>% 
  filter(date > ymd("2014-01-01")) %>% 
  arrange(desc(date)) %>% 
  head(20)
  
daily %>% 
  filter(date >= ymd("2014-01-01"),
         date < ymd("2022-01-01"),
         keyword %in% c("BLM", "MeToo")
         ) %>% 
  ggplot(aes(date, mean, color=keyword, fill=keyword, ymin=mean-se, ymax=mean+se)) + 
  #geom_line() +
  #geom_ribbon(alpha=.2) +
  geom_smooth(method="loess", se=T) +
  geom_vline(xintercept = as.numeric(ymd("2017-10-1")), linetype=2) +
  geom_vline(xintercept = as.numeric(ymd("2020-5-1")), linetype=2) +
  scale_x_date(date_breaks = "2 months", date_labels = "%m - %y",
               expand = expansion(mult = c(0, 0))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

daily %>% 
  filter(date >= ymd("2014-01-01"),
         date < ymd("2022-01-01"),
         keyword %in% c("BLM", "MeToo")
  ) %>% 
  group_by(keyword) %>%
  mutate(fit = lm(mean ~ log10(tweets))$fitted.values) %>%
  slice_max(fit) %>% 
  ungroup() %>% 
  mutate(label = keyword) %>% 
  right_join(daily) %>% 
  filter(date >= ymd("2014-01-01"),
         date < ymd("2022-01-01"),
         keyword %in% c("BLM", "MeToo")
  ) %>% 
  ggplot(aes(tweets, mean, fill=keyword)) +
  geom_smooth(aes(color=keyword), method="lm") +
  scale_x_log10(
                limits = c(100,10^7),
                breaks = scales::log_breaks(6),
                labels = scales::comma,
                expand = expansion(mult = c(0, 0.02))
                ) +
  scale_y_continuous(
                     expand = expansion(mult = c(0, 0))) +
  labs(
    x = "Daily Count of Tweets Using the Keyword",
    y = "Mean Concept Mover's Distance From Keyword",
    color = "Keyword:",
    fill = "Keyword:",
    title = "Effect of Social Movements' Daily Visibility on Twitter on Reference to Those Movemnts in Film Discussion Threads on Reddit",
    caption = "Data from Jan. 1, 2014 to Dec. 31, 2021."
  ) +
  ggrepel::geom_text_repel(aes(y=fit, label=label), na.rm=T, show.legend = F,
                           direction = "y", nudge_y = .001,
                           min.segment.length = Inf
             ) +
  theme(legend.position = "none")

# At the comment level ----
bravo <- comments %>% 
  filter(date >= ymd("2014-01-01"),
         date < ymd("2022-01-01")) %>% 
  reshape2::melt(measure.vars=centroid_words,
       variable.name="keyword",
       value.name = "CMD")

bravo %>%
  ggplot(aes(date, CMD, color=keyword, fill=keyword)) + 
  geom_smooth(method = lm) +
  geom_vline(xintercept = as.numeric(ymd("2017-10-1")), linetype=2) +
  geom_vline(xintercept = as.numeric(ymd("2020-5-1")), linetype=2) +
  scale_x_date(date_breaks = "2 months", date_labels = "%m - %y",
               expand = expansion(mult = c(0, 0))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

# Table export ----

c(m1,m2,m3n) %>% 
  map(get_random) %>% 
  bind_rows(.id = "Model") %>% 
  rename(vpc = icc) %>%
  mutate(zzz = NA) %>% 
  pivot_wider(
    names_from = "Model",
    values_from = 4:6,
    names_glue = "M{Model}_{.value}"
  ) %>% 
  select(order(colnames(.))) %>%
  select(grp, var1, everything()) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) %>% 
      # rename_with(~ str_c("{", .x, "}")) %>% 
      xtable() %>% 
      print(
        include.rownames = F,
        include.colnames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        comment = F,
        only.contents = T
      ) %>% 
  str_replace_all("\\\\", "\\\\\\\\") %>% 
  print()

ll <- logLik(model)[1]

map(c(m1,m2),
  ~ logLik(.)[1]) %>% 
  as_tibble_col() %>% 
  unnest_longer(value) %>% 
  mutate("name" = 1:nrow(.),
         # value = str_c("{", as.character(as.integer(value)), "}")
         ) %>% 
  group_by(name) %>% 
  mutate(
         y = NA,
         z = NA) %>% 
  ungroup() %>% 
  pivot_wider(names_from = "name",
              values_from = c(value, y, z),
              names_glue = "M{name}_{.value}") %>% 
  mutate(a = "LogLik",
         b = NA) %>% 
  select(order(colnames(.))) %>% 
  xtable() %>% 
      print(
        include.rownames = F,
        include.colnames = F,
        #math.style.negative = T,
        print.results = F,
        booktabs = T,
        comment = F,
        only.contents = T
      ) %>%
  # str_replace_all("[-\d\.]+")
  str_replace_all("\\\\", "\\\\\\\\") %>% 
  cat()
# Vote count over time ----
# There seems to be a drop in n of votes due to covid (at the top end)
# Other potential reasons: 
# there has been less chance for voting on more recent films
# more recent films are more likely to have discussion threads, even if they are less popular (bottom end)

comments %>% 
  group_by(submission_id) %>% 
  summarise(Date = min(Date), vote_count = min(vote_count)) %>% 
  ggplot(aes(Date, vote_count)) + 
  geom_point() + 
  geom_smooth(method=lm) + 
  geom_vline(xintercept = ymd("2020-03-01"))

comments %>%
  mutate(pop = cut_number(vote_count, 3)) %>% 
  ggplot(aes(thread_date, discrimination_centroid)) +
  geom_smooth(method = "lm", linetype = 2) +
  geom_smooth(aes( color = pop, fill = pop), method = "lm") +
  theme(legend.position = "top") +
  labs(
    title = "Vote count into\n5 groups with equal n(obs)",
    color = element_blank(),
    fill = element_blank()
  )


comments %>% 
  group_by(submission_id) %>% 
  slice_head(n=1) %>% 
  ungroup() %>% 
  ggplot(aes(thread_age, sexism_keywords)) +
  geom_smooth(color="red", fill="red", method = "lm") +
  geom_smooth(aes(y=racism_keywords), color="blue", fill="blue", method = "lm")
# ranef ----
pred_values %>% 
  mutate(x = discrimination_centroid - fit3b) %>% 
  arrange(x)

pred_values %>% 
  mutate(label = case_when(
    abs(Date - date_metoo) == min(abs(Date - date_metoo)) ~ "Alyssa Milano\nTweet",
    T ~ NA_character_)) %>% 
  group_by(label) %>% 
  mutate(label = if_else(!duplicated(label), label, NA_character_)) %>% 
  ungroup() %>% 
  ggplot(aes(Date, m3, label=label)) +
  # geom_line(aes(y=value, color = "Actual Means")) +
  # geom_smooth(aes(y=value, color = "Loess Smoothed Actual Means"), method = "loess",se=F) +
  geom_point(aes(color = "Predicted Means")) +
  # geom_smooth(aes(color = "Loess Smoothed Predicted Means"), method = "loess", se=F) +
  geom_vline(xintercept = as.numeric(date_metoo), linetype=2) +
  # scale_y_continuous(limits = c(0.025, 0.025)) +
  scale_x_date(date_breaks = "2 months", date_labels = "%b '%y",
               expand = expansion(mult = c(0, 0))) +
  # scale_color_manual(values = lm_colors) +
  # ggrepel::geom_text_repel(color="black",
  #                          na.rm=T, show.legend = F,
  #                          # direction = "y", 
  #                          nudge_y = .05,
  #                          min.segment.length = Inf
  # ) +
  annotate("text", date_metoo, 0.075, label="Alyssa Milano Tweet", angle=90, vjust=-.3) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position = "top",
        legend.title = element_blank()) +
  labs(title = "Mean Predicted Values of Sexism-Related Comments Grouped by Submission",
       # subtitle = "Formula: CMD from sexism ~ log( #MeToo tweets) * cumulative frequency of #MeToo tweets",
       x = element_blank(),
       y = "CMD from Sexism Centroid")
# random slope models ----
random_slope_models <- as.list(c(movements, "thread_age", "comment_age", "sexism_keywords", "racism_keywords")) %>% 
  set_names() %>% 
  map(
    ~ lmer(paste0("discrimination_centroid ~ thread_age + `thread_age^2` + comment_age + politics_comments + MeToo + BLM + OscarsSoWhite + sexism_keywords + racism_keywords + (1|submission_id) + (1+", .x, "|author)"), 
           data = comments, REML = FALSE, 
           control = lmerControl(optimizer ="Nelder_Mead")
    )
  )
# viz ----

predict_submission <- function(.data, model) {
  model_name <- deparse(substitute(model))
  df <- ranef(model, condVar=F, whichel="submission_id") %>% 
    as_tibble() %>% 
    mutate({{ model_name }} := condval #+ fixef(model)[1]
           ) %>% 
    select(grp, {{ model_name }}) %>% 
    rename("submission_id" = grp)
    left_join(.data, df)
}

submissions <- submissions %>% 
  mutate(pred_fixed = predict(!!m4, ., re.form = NA),
         pred_f_m3b = predict(!!m3b, ., re.form = NA),
         pred_vals = predict(!!m4, ., re.form = ~(1|submission_id)))

submissions <- submissions %>%
  predict_submission(m1) %>% 
  predict_submission(m3b) %>% 
  predict_submission(m3) %>% 
  predict_submission(m4)

pred_fixed <- fixef(m4)
pred_fixed["thread_age"]

tibble(
  thread_age = seq(min(comments$thread_age), max(comments$thread_age), .001)
) %>% 
  mutate(
    pred = thread_age*pred_fixed["thread_age"]+thread_age^2*pred_fixed["`thread_age^2`"]+pred_fixed["(Intercept)"]
  ) %>% 
  ggplot(aes(thread_age, pred)) +
  geom_line()

submissions %>%
  ggplot(aes(film_title, pred_fixed)) +
  geom_point()

submissions %>% 
  ggplot(aes(thread_age, pred_f_m3b)) +
  geom_line()

submissions %>% 
  filter(abs(m4) > .5) %>% 
  arrange(m4) %>% 
  ggplot(aes(fct_inorder(film_title), m4)) +
  geom_point() +
  coord_flip()

submissions %>% 
  reshape2::melt(
    measure.vars = c("m1", "m3b", "m3", "m4"),
    variable.name = "Model",
    value.name = "Ranef"
    ) %>%  
  as_tibble() %>% 
  ggplot(aes(thread_age, Ranef, color = Model)) +
  geom_point()

submissions %>% 
  filter(abs(m1) > .5) %>% 
  arrange(m1) %>% 
  reshape2::melt(
    measure.vars = c("m1", "m3b", "m3", "m4"),
    variable.name = "Model",
    value.name = "Ranef"
    ) %>%  
  as_tibble() %>% 
  ggplot(aes(fct_inorder(film_title), Ranef, color=Model)) +
  geom_point() +
  coord_flip()
```